{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1a10x0qWMSONp4T0Kychkvzby7VTtlreI","timestamp":1744585464758}],"gpuType":"A100","collapsed_sections":["kQAcF587RBcK","QF0mmC7KRgWw","8vsvgPeORK6P"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"54c3c6d46d064c1cb5c88d546c59c88d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ffe28b58ca9540419e812f860d88424c","IPY_MODEL_cb14b04894e541b59868dd656aeca5db","IPY_MODEL_2b6a3254517e4d1783730b3335f1ee9e"],"layout":"IPY_MODEL_a3a82951e8934c0b918234d4053f2a77"}},"ffe28b58ca9540419e812f860d88424c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c701a66430c44dab044721e76a52ec2","placeholder":"​","style":"IPY_MODEL_bb878bcefb4b43909655f4ea117270ba","value":"Map: 100%"}},"cb14b04894e541b59868dd656aeca5db":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_03883f14ce7b4716b9e0841a272bd307","max":100000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a061492a6b2644848aeb940486e19171","value":100000}},"2b6a3254517e4d1783730b3335f1ee9e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6bccbe034f2045ee9d6a19a021954a2a","placeholder":"​","style":"IPY_MODEL_58c2e397692e445d862ec6b42def76f4","value":" 100000/100000 [00:17&lt;00:00, 5930.11 examples/s]"}},"a3a82951e8934c0b918234d4053f2a77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c701a66430c44dab044721e76a52ec2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb878bcefb4b43909655f4ea117270ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"03883f14ce7b4716b9e0841a272bd307":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a061492a6b2644848aeb940486e19171":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6bccbe034f2045ee9d6a19a021954a2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58c2e397692e445d862ec6b42def76f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"kQAcF587RBcK"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CfOFhTlUPoos","executionInfo":{"status":"ok","timestamp":1744586869501,"user_tz":420,"elapsed":86823,"user":{"displayName":"Marcos Geraldo","userId":"04095741566103828065"}},"outputId":"c1954c29-0cb0-414a-a65c-e6b4bc549d31","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.8 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.8 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nvjitlink-cu12==12.4.127\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m150.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m130.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m137.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip3 install --upgrade pip -q\n","!pip3 install nvidia-cublas-cu12==12.4.5.8 nvidia-cuda-cupti-cu12==12.4.127 nvidia-cuda-nvrtc-cu12==12.4.127 nvidia-cuda-runtime-cu12==12.4.127 nvidia-cudnn-cu12==9.1.0.70 nvidia-cufft-cu12==11.2.1.3 nvidia-curand-cu12==10.3.5.147 nvidia-cusolver-cu12==11.6.1.9 nvidia-cusparse-cu12==12.3.1.170 nvidia-nvjitlink-cu12==12.4.127\n","!pip3 install nltk emoji==0.6.0 -q\n","!pip3 install torchinfo -q\n","!pip3 install kagglehub -q\n","!pip3 install kaggle -q\n","!pip3 install transformers -q\n","!pip3 install evaluate -q"]},{"cell_type":"code","source":["!pip3 install fsspec==2025.3.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HPuzh4ZhPttf","executionInfo":{"status":"ok","timestamp":1744586912212,"user_tz":420,"elapsed":2019,"user":{"displayName":"Marcos Geraldo","userId":"04095741566103828065"}},"outputId":"dbb587a6-f181-4883-cda0-326acb28ca02","collapsed":true},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fsspec==2025.3.0\n","  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n","Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n","Installing collected packages: fsspec\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.12.0\n","    Uninstalling fsspec-2024.12.0:\n","      Successfully uninstalled fsspec-2024.12.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datasets 3.5.0 requires fsspec[http]<=2024.12.0,>=2023.1.0, but you have fsspec 2025.3.0 which is incompatible.\n","gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed fsspec-2025.3.0\n"]}]},{"cell_type":"code","source":["import os\n","from google.colab import drive\n","\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OmBB_TrLPvTo","executionInfo":{"status":"ok","timestamp":1744586935286,"user_tz":420,"elapsed":18921,"user":{"displayName":"Marcos Geraldo","userId":"04095741566103828065"}},"outputId":"f4e7dc5f-fb8d-41f1-8bf0-3d11054b0562"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# list the elements in the current working directory\n","print(\"current directory: \", os.getcwd())\n","#os.chdir('content/drive/MyDrive/DATASCI 266/Project') # Use when working on Berkeley's Google Drive\n","os.chdir('drive/MyDrive/Knowledge/Berkeley/DATASCI 266/Project') # Use when working on Personal Google Drive\n","os.listdir()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4TDpRr_wPwy0","executionInfo":{"status":"ok","timestamp":1744586937763,"user_tz":420,"elapsed":1576,"user":{"displayName":"Marcos Geraldo","userId":"04095741566103828065"}},"outputId":"bfeca9fc-1383-4071-f76a-09dde6394b6e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["current directory:  /content\n"]},{"output_type":"execute_result","data":{"text/plain":["['Project Proposal.gdoc',\n"," 'TweetNormalizer.py',\n"," '__pycache__',\n"," 'results_baseline',\n"," 'wandb',\n"," 'Tweets_full_normalized.csv',\n"," 'baseline_model',\n"," 'bertweet_model',\n"," 'bertkeep_model',\n"," 'Copy of Lora_(Roberta_Large)_pytorch.ipynb',\n"," 'filtered_tweets.csv',\n"," 'filtered_sample_2500.csv',\n"," 'Normalized_filtered_tweets.csv',\n"," 'Crypto Sentiment Analysis.ipynb',\n"," 'labelled_normalized_dataset.csv',\n"," 'small_train_dataset.csv',\n"," 'small_eval_dataset.csv',\n"," 'small_eval_dataset_filtered.csv',\n"," 'small_train_dataset_filtered.csv',\n"," 'labelled_dataset.csv',\n"," 'bertkeep_model5',\n"," 'bertweet_model_6',\n"," 'bertweet_model_7',\n"," 'bertweet_model_8',\n"," 'bertweet_model_9',\n"," 'bertkeep_model_9',\n"," 'bertkeep_model_10',\n"," 'bertkeep_model_11',\n"," 'Paper',\n"," 'tweets_sentiment.csv',\n"," 'File Index.gsheet',\n"," 'Crypto Sentiment Analysis_Data Preparation.ipynb',\n"," 'Copy of Crypto Sentiment Analysis_BERTweet.ipynb',\n"," 'Copy of Crypto Sentiment Analysis.ipynb',\n"," 'Crypto Sentiment Analysis_BERTweet.ipynb',\n"," 'large_balanced_dataset.csv',\n"," 'Model_Test_MG.ipynb',\n"," 'Untitled0.ipynb']"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["import kagglehub\n","import pandas as pd\n","import numpy as np\n","\n","import torch\n","from torchinfo import summary # to show the summary of the models\n","import evaluate # for metric evaluation during training from Huggingface\n","from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification, pipeline, Trainer, TrainingArguments\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","from TweetNormalizer import normalizeTweet\n","from datasets import Dataset # from Huggingface\n","\n","from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n"],"metadata":{"id":"-swdlyYVPzQ0","executionInfo":{"status":"ok","timestamp":1744586961133,"user_tz":420,"elapsed":17878,"user":{"displayName":"Marcos Geraldo","userId":"04095741566103828065"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Data Loading"],"metadata":{"id":"QF0mmC7KRgWw"}},{"cell_type":"code","source":["try:\n","  df_large = pd.read_csv('large_balanced_dataset.csv')\n","except:\n","  # Load the full dataset if not already in memory\n","  df2 = pd.read_csv('/content/drive/MyDrive/Project/labelled_dataset.csv')\n","  df2['tweet'] = df2['tweet'].apply(normalizeTweet)\n","\n","  # Desired total sample size\n","  target_size = 100_000\n","\n","  # Check class distribution\n","  label_counts = df2['label'].value_counts(normalize=True)\n","  print(\"Original label distribution (%):\\n\", label_counts * 100)\n","\n","  # Compute number of samples per class\n","  samples_per_class = (label_counts * target_size).round().astype(int)\n","\n","  # Sample from each class proportionally\n","  df_sampled = pd.concat([\n","      df2[df2['label'] == label].sample(n=n, random_state=42)\n","      for label, n in samples_per_class.items()\n","  ])\n","\n","  # Shuffle the dataset\n","  df_sampled = df_sampled.sample(frac=1, random_state=42).reset_index(drop=True)\n","\n","  # Check sampled distribution\n","  print(\"\\nSampled label distribution (%):\\n\", df_sampled['label'].value_counts(normalize=True) * 100)\n","\n","  # Save if desired\n","  df_sampled.to_csv(\"large_balanced_dataset.csv\", index=False)\n"],"metadata":{"id":"kA1NLykFSCMq","executionInfo":{"status":"ok","timestamp":1744591789934,"user_tz":420,"elapsed":678,"user":{"displayName":"Marcos Geraldo","userId":"04095741566103828065"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Ensure text is normalized the same way\n","df_large['tweet'] = df_large['tweet'].apply(normalizeTweet)\n","\n","# Convert to Hugging Face Dataset\n","dataset_large = Dataset.from_pandas(df_large, preserve_index=False)"],"metadata":{"id":"ZsaiJhBkVC0v","executionInfo":{"status":"ok","timestamp":1744591832589,"user_tz":420,"elapsed":22247,"user":{"displayName":"Marcos Geraldo","userId":"04095741566103828065"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def preprocess_tweet(data):\n","    encoded = tokenizer.batch_encode_plus(\n","        data['tweet'],\n","        max_length=280,\n","        padding='max_length',\n","        truncation=True,\n","        return_attention_mask=True,\n","        return_token_type_ids=True\n","    )\n","    encoded['label'] = data['label']\n","    return encoded\n","\n","dataset_large = dataset_large.map(preprocess_tweet, batched=True)\n","dataset_large.set_format(type='torch', columns=['input_ids', 'attention_mask', 'token_type_ids', 'label'])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["54c3c6d46d064c1cb5c88d546c59c88d","ffe28b58ca9540419e812f860d88424c","cb14b04894e541b59868dd656aeca5db","2b6a3254517e4d1783730b3335f1ee9e","a3a82951e8934c0b918234d4053f2a77","3c701a66430c44dab044721e76a52ec2","bb878bcefb4b43909655f4ea117270ba","03883f14ce7b4716b9e0841a272bd307","a061492a6b2644848aeb940486e19171","6bccbe034f2045ee9d6a19a021954a2a","58c2e397692e445d862ec6b42def76f4"]},"id":"5ahozOZnV9y0","executionInfo":{"status":"ok","timestamp":1744591854178,"user_tz":420,"elapsed":17597,"user":{"displayName":"Marcos Geraldo","userId":"04095741566103828065"}},"outputId":"0308cec8-0ba7-44a6-9e2a-98ce78608b2b"},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/100000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54c3c6d46d064c1cb5c88d546c59c88d"}},"metadata":{}}]},{"cell_type":"markdown","source":["# Model Loading\n","\n","Here we load the models to evaluate and attach them again to the base model."],"metadata":{"id":"8vsvgPeORK6P"}},{"cell_type":"code","source":["# Load model 6\n","model_dir = \"./bertweet_model_6\"\n","\n","# Load the LoRA config first\n","peft_config = PeftConfig.from_pretrained(model_dir)\n","\n","# Load base model\n","baseline_model = AutoModelForSequenceClassification.from_pretrained(\"./baseline_model\")\n","\n","# Load the fine-tuned LoRA adapter\n","model = PeftModel.from_pretrained(baseline_model, model_dir)\n"],"metadata":{"id":"35LxYEKNPza0","executionInfo":{"status":"ok","timestamp":1744590740806,"user_tz":420,"elapsed":16073,"user":{"displayName":"Marcos Geraldo","userId":"04095741566103828065"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["summary(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ol0yK4ZcfqXo","executionInfo":{"status":"ok","timestamp":1744590744872,"user_tz":420,"elapsed":414,"user":{"displayName":"Marcos Geraldo","userId":"04095741566103828065"}},"outputId":"b80c3162-f4cc-47eb-f27b-ab8c066e4d3a"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["====================================================================================================\n","Layer (type:depth-idx)                                                      Param #\n","====================================================================================================\n","PeftModelForSequenceClassification                                          --\n","├─LoraModel: 1-1                                                            --\n","│    └─RobertaForSequenceClassification: 2-1                                --\n","│    │    └─RobertaModel: 3-1                                               (354,703,360)\n","│    │    └─ModulesToSaveWrapper: 3-2                                       2,105,350\n","====================================================================================================\n","Total params: 356,808,710\n","Trainable params: 1,052,675\n","Non-trainable params: 355,756,035\n","===================================================================================================="]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\"./baseline_model\")\n"],"metadata":{"id":"q2bR5lv3U3iw","executionInfo":{"status":"ok","timestamp":1744591577726,"user_tz":420,"elapsed":758,"user":{"displayName":"Marcos Geraldo","userId":"04095741566103828065"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# LoRA Model Evaluation"],"metadata":{"id":"BshSQpflRyta"}},{"cell_type":"code","source":["from tqdm import tqdm\n","from sklearn.metrics import classification_report\n","\n","# Put model in eval mode and move to appropriate device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","model.eval()\n","\n","all_preds = []\n","all_labels = []\n","\n","# Disable gradients for faster inference\n","with torch.no_grad():\n","    for batch in tqdm(dataset_large.iter(batch_size=32), total=len(dataset_large)//32):\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        token_type_ids = batch['token_type_ids'].to(device)\n","        labels = batch['label'].to(device)\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","        preds = torch.argmax(outputs.logits, axis=1)\n","\n","        all_preds.extend(preds.cpu().numpy())\n","        all_labels.extend(labels.cpu().numpy())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZLPTBaXzWBCH","outputId":"3c7204a8-0e31-4702-d249-124270e20c3a","executionInfo":{"status":"ok","timestamp":1744592998942,"user_tz":420,"elapsed":1071871,"user":{"displayName":"Marcos Geraldo","userId":"04095741566103828065"}}},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 3125/3125 [17:51<00:00,  2.92it/s]\n"]}]},{"cell_type":"code","source":["print(classification_report(all_labels, all_preds))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cty4wvb175tM","executionInfo":{"status":"ok","timestamp":1744594599043,"user_tz":420,"elapsed":25,"user":{"displayName":"Marcos Geraldo","userId":"04095741566103828065"}},"outputId":"8e819aaa-1ab2-414d-8a49-dc440aa90670"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.95      0.59      0.73     62437\n","           1       0.37      0.83      0.51      9581\n","           2       0.55      0.77      0.64     27982\n","\n","    accuracy                           0.67    100000\n","   macro avg       0.62      0.73      0.63    100000\n","weighted avg       0.78      0.67      0.68    100000\n","\n"]}]},{"cell_type":"markdown","source":["# Baseline Model Evaluation"],"metadata":{"id":"bt-qszW5R8zH"}},{"cell_type":"code","source":["baseline_model = AutoModelForSequenceClassification.from_pretrained(\"./baseline_model\")\n","summary(baseline_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ff_7Or9HIQ9e","executionInfo":{"status":"ok","timestamp":1744597952503,"user_tz":420,"elapsed":271,"user":{"displayName":"Marcos Geraldo","userId":"04095741566103828065"}},"outputId":"216ed37b-3a9b-4f03-81a3-4a88da074d7d"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["==========================================================================================\n","Layer (type:depth-idx)                                            Param #\n","==========================================================================================\n","RobertaForSequenceClassification                                  --\n","├─RobertaModel: 1-1                                               --\n","│    └─RobertaEmbeddings: 2-1                                     --\n","│    │    └─Embedding: 3-1                                        51,471,360\n","│    │    └─Embedding: 3-2                                        526,336\n","│    │    └─Embedding: 3-3                                        1,024\n","│    │    └─LayerNorm: 3-4                                        2,048\n","│    │    └─Dropout: 3-5                                          --\n","│    └─RobertaEncoder: 2-2                                        --\n","│    │    └─ModuleList: 3-6                                       302,309,376\n","├─RobertaClassificationHead: 1-2                                  --\n","│    └─Linear: 2-3                                                1,049,600\n","│    └─Dropout: 2-4                                               --\n","│    └─Linear: 2-5                                                3,075\n","==========================================================================================\n","Total params: 355,362,819\n","Trainable params: 355,362,819\n","Non-trainable params: 0\n","=========================================================================================="]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["# Put model in eval mode and move to appropriate device\n","baseline_model.to(device)\n","baseline_model.eval()\n","\n","all_preds = []\n","all_labels = []\n","\n","# Disable gradients for faster inference\n","with torch.no_grad():\n","    for batch in tqdm(dataset_large.iter(batch_size=32), total=len(dataset_large)//32):\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        token_type_ids = batch['token_type_ids'].to(device)\n","        labels = batch['label'].to(device)\n","\n","        outputs = baseline_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","        preds = torch.argmax(outputs.logits, axis=1)\n","\n","        all_preds.extend(preds.cpu().numpy())\n","        all_labels.extend(labels.cpu().numpy())\n","print(classification_report(all_labels, all_preds))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ika0Jbut8XwF","executionInfo":{"status":"ok","timestamp":1744598999623,"user_tz":420,"elapsed":1037283,"user":{"displayName":"Marcos Geraldo","userId":"04095741566103828065"}},"outputId":"40152528-5ed3-4e2b-807d-fbfc0940082a"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 3125/3125 [17:16<00:00,  3.02it/s]"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.72      0.56      0.63     62437\n","           1       0.18      0.40      0.25      9581\n","           2       0.38      0.42      0.40     27982\n","\n","    accuracy                           0.51    100000\n","   macro avg       0.43      0.46      0.43    100000\n","weighted avg       0.58      0.51      0.53    100000\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["print(classification_report(all_labels, all_preds))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VD-dh4FeFSvu","executionInfo":{"status":"ok","timestamp":1744599148821,"user_tz":420,"elapsed":76,"user":{"displayName":"Marcos Geraldo","userId":"04095741566103828065"}},"outputId":"28247a0f-271d-4a26-c34a-049c2dce7164"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.72      0.56      0.63     62437\n","           1       0.18      0.40      0.25      9581\n","           2       0.38      0.42      0.40     27982\n","\n","    accuracy                           0.51    100000\n","   macro avg       0.43      0.46      0.43    100000\n","weighted avg       0.58      0.51      0.53    100000\n","\n"]}]}]}